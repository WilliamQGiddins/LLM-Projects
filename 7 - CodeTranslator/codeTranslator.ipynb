{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b5dcc4",
   "metadata": {},
   "source": [
    "# Code Translator that compares different frontier and open source models to determine which are most efficient to compare busineess cost allowing users to run the converted code on their own machine to compare run times\n",
    "\n",
    "Utilizes:\n",
    "    - Python code execution\n",
    "    - System spec reading\n",
    "    - Subprocesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "454dd779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import subprocess\n",
    "from IPython.display import Markdown, display\n",
    "from system_info import retrieve_system_info, rust_toolchain_info, go_toolchain_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec46fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize env variables\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "grok_api_key = os.getenv('GROK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "openrouter_api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")\n",
    "\n",
    "if grok_api_key:\n",
    "    print(f\"Grok API Key exists and begins {grok_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Grok API Key not set\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set\")\n",
    "\n",
    "if openrouter_api_key:\n",
    "    print(f\"OpenRouter API Key exists and begins {openrouter_api_key[:6]}\")\n",
    "else:\n",
    "    print(\"OpenRouter API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f4ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize clients\n",
    "\n",
    "openai = OpenAI()\n",
    "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "grok_url = \"https://api.x.ai/v1\"\n",
    "groq_url = \"https://api.groq.com/openai/v1\"\n",
    "ollama_url = \"http://localhost:11434/v1\"\n",
    "openrouter_url = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "anthropic = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=gemini_url)\n",
    "grok = OpenAI(api_key=grok_api_key, base_url=grok_url)\n",
    "groq = OpenAI(api_key=groq_api_key, base_url=groq_url)\n",
    "ollama = OpenAI(api_key=\"ollama\", base_url=ollama_url)\n",
    "openrouter = OpenAI(api_key=openrouter_api_key, base_url=openrouter_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcf0e347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your models\n",
    "\n",
    "models = [\"gpt-5\", \"claude-sonnet-4-5-20250929\", \"grok-4\", \"gemini-2.5-pro\", \"qwen2.5-coder\", \"deepseek-coder-v2\", \"gpt-oss:20b\", \"qwen/qwen3-coder-30b-a3b-instruct\", \"openai/gpt-oss-120b\", \"llama3.2\" ]\n",
    "\n",
    "clients = {\"gpt-5\": openai, \"claude-sonnet-4-5-20250929\": anthropic, \"grok-4\": grok, \"gemini-2.5-pro\": gemini, \"openai/gpt-oss-120b\": groq, \"qwen2.5-coder\": ollama, \"deepseek-coder-v2\": ollama, \"gpt-oss:20b\": ollama, \"qwen/qwen3-coder-30b-a3b-instruct\": openrouter, \"llama3.2\" : ollama}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28ad3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coding languages\n",
    "\n",
    "system_info = retrieve_system_info()\n",
    "rust_info = rust_toolchain_info()\n",
    "go_info = go_toolchain_info()\n",
    "\n",
    "languageExtension = {\"cpp\": \"cpp\", \"rust\": \"rs\", \"go\": \"go\" }\n",
    "languages = [\"cpp\", \"rust\", \"go\" ]\n",
    "toolchain = {\"cpp\": 'N/A' , \"rust\": rust_info, \"go\": go_info }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c1a0904",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_command = [\n",
    "    \"/Users/gidd/.cargo/bin/rustc\",\n",
    "    \"main.rs\",\n",
    "    \"-C\", \"opt-level=3\",\n",
    "    \"-C\", \"target-cpu=native\",\n",
    "    \"-C\", \"codegen-units=1\",\n",
    "    \"-C\", \"lto=fat\",\n",
    "    \"-C\", \"panic=abort\",\n",
    "    \"-C\", \"strip=symbols\",\n",
    "    \"-o\", \"main\",\n",
    "]\n",
    "\n",
    "run_command = [\"./main\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81ccc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check System config\n",
    "\n",
    "def checkSystem(language):\n",
    "    info = toolchain[language]\n",
    "    extension = languageExtension[language]\n",
    "\n",
    "    message = f\"\"\"\n",
    "    Here is a report of the system information for my computer.\n",
    "    I want to run a {language} compiler to compile a single {language} file called main.{extension} and then execute it in the simplest way possible.\n",
    "    Please reply with whether I need to install a {language} toolchain to do this. If so, please provide the simplest step by step instructions to do so.\n",
    "\n",
    "    If I'm already set up to compile {language} code, then I'd like to run something like this in Python to compile and execute the code:\n",
    "    ```python\n",
    "    compile_command = # something here - to achieve the fastest possible runtime performance\n",
    "    compile_result = subprocess.run(compile_command, check=True, text=True, capture_output=True)\n",
    "    run_command = # something here\n",
    "    run_result = subprocess.run(run_command, check=True, text=True, capture_output=True)\n",
    "    return run_result.stdout\n",
    "    ```\n",
    "    Please tell me exactly what I should use for the compile_command and run_command.\n",
    "    Have the maximum possible runtime performance in mind; compile time can be slow. Fastest possible runtime performance for this platform is key.\n",
    "    Reply with the commands in array format like:\n",
    "\n",
    "    Compile Command\n",
    "    {compile_command}\n",
    "\n",
    "    Run Command\n",
    "    {run_command}\n",
    "    \n",
    "    System information:\n",
    "    {system_info}\n",
    "\n",
    "\n",
    "    {f'{language} toolchain information:\\n{info}' if language != 'cpp' else ''}\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai.chat.completions.create(model=models[0], messages=[{\"role\": \"user\", \"content\": message}])\n",
    "    return response.choices[0].message.content\n",
    "    #response = ollama.chat.completions.create(model=models[9], messages=[{\"role\": \"user\", \"content\": message}])\n",
    "    #display(Markdown(response.choices[0].message.content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82b71f1",
   "metadata": {},
   "source": [
    "# Edit compile command for your system and chosen language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f53ec7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile command example\n",
    "\n",
    "compile_command = [\n",
    "    \"/Users/gidd/.cargo/bin/rustc\",\n",
    "    \"main.rs\",\n",
    "    \"-C\", \"opt-level=3\",\n",
    "    \"-C\", \"target-cpu=native\",\n",
    "    \"-C\", \"codegen-units=1\",\n",
    "    \"-C\", \"lto=fat\",\n",
    "    \"-C\", \"panic=abort\",\n",
    "    \"-C\", \"strip=symbols\",\n",
    "    \"-o\", \"main\",\n",
    "]\n",
    "\n",
    "run_command = [\"./main\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a1537ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messages(python, language):\n",
    "    system_prompt = f\"\"\"\n",
    "    Your task is to convert Python code into high performance {language} code.\n",
    "    Respond only with {language} code. Do not provide any explanation other than occasional comments.\n",
    "    The {language} response needs to produce an identical output in the fastest possible time.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    Port this Python code to {language} with the fastest possible implementation that produces identical output in the least time.\n",
    "    The system information is:\n",
    "    {system_info}\n",
    "    Your response will be written to a file called main.{language} and then compiled and executed; the compilation command is:\n",
    "    {compile_command}\n",
    "    Respond only with {language} code.\n",
    "    Python code to port:\n",
    "\n",
    "    ```python\n",
    "    {python}\n",
    "    \"\"\"\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d01230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(code, language):\n",
    "    extension = languageExtension[language]\n",
    "    with open(f\"main.{extension}\", \"w\") as f:\n",
    "        f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a6c88fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def portCode(model, python, language):\n",
    "    client = clients[model]\n",
    "    reasoning_effort = \"high\" if 'gpt' in model else None\n",
    "    response = client.chat.completions.create(model=model, messages=get_messages(python, language), reasoning_effort=reasoning_effort)\n",
    "    reply = response.choices[0].message.content\n",
    "    reply = reply.replace('```cpp','').replace('```rust','').replace('```go','').replace('```','')\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fee994e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_python(code):\n",
    "    globals_dict = {\"__builtins__\": __builtins__}\n",
    "\n",
    "    buffer = io.StringIO()\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = buffer\n",
    "\n",
    "    try:\n",
    "        exec(code, globals_dict)\n",
    "        output = buffer.getvalue()\n",
    "    except Exception as e:\n",
    "        output = f\"Error: {e}\"\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fda4b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_run(code):\n",
    "    write_output(code)\n",
    "    try:\n",
    "        subprocess.run(compile_command, check=True, text=True, capture_output=True)\n",
    "        run_result = subprocess.run(run_command, check=True, text=True, capture_output=True)\n",
    "        return run_result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"An error occurred:\\n{e.stderr}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "779e9619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example python code\n",
    "\n",
    "python_hard = \"\"\"# Be careful to support large numbers\n",
    "\n",
    "def lcg(seed, a=1664525, c=1013904223, m=2**32):\n",
    "    value = seed\n",
    "    while True:\n",
    "        value = (a * value + c) % m\n",
    "        yield value\n",
    "        \n",
    "def max_subarray_sum(n, seed, min_val, max_val):\n",
    "    lcg_gen = lcg(seed)\n",
    "    random_numbers = [next(lcg_gen) % (max_val - min_val + 1) + min_val for _ in range(n)]\n",
    "    max_sum = float('-inf')\n",
    "    for i in range(n):\n",
    "        current_sum = 0\n",
    "        for j in range(i, n):\n",
    "            current_sum += random_numbers[j]\n",
    "            if current_sum > max_sum:\n",
    "                max_sum = current_sum\n",
    "    return max_sum\n",
    "\n",
    "def total_max_subarray_sum(n, initial_seed, min_val, max_val):\n",
    "    total_sum = 0\n",
    "    lcg_gen = lcg(initial_seed)\n",
    "    for _ in range(20):\n",
    "        seed = next(lcg_gen)\n",
    "        total_sum += max_subarray_sum(n, seed, min_val, max_val)\n",
    "    return total_sum\n",
    "\n",
    "# Parameters\n",
    "n = 10000         # Number of random numbers\n",
    "initial_seed = 42 # Initial seed for the LCG\n",
    "min_val = -10     # Minimum value of random numbers\n",
    "max_val = 10      # Maximum value of random numbers\n",
    "\n",
    "# Timing the function\n",
    "import time\n",
    "start_time = time.time()\n",
    "result = total_max_subarray_sum(n, initial_seed, min_val, max_val)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Total Maximum Subarray Sum (20 runs):\", result)\n",
    "print(\"Execution Time: {:.6f} seconds\".format(end_time - start_time))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3b9a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradio\n",
    "\n",
    "def update_get_compile(language):\n",
    "    return gr.Button(value=f\"Generate compile command for {language} to replace command_compile\")\n",
    "\n",
    "def update_code_output(language):\n",
    "    return gr.Code(label=f\"{language} (generated)\")\n",
    "\n",
    "def update_convert_output(language):\n",
    "    return gr.Button(value=f\"Port to {language}\")\n",
    "\n",
    "def update_code_run_output(language):\n",
    "    return gr.Button(value=f\"Run {language}\")\n",
    "\n",
    "def update_code_out_output(language):\n",
    "    return gr.TextArea(label=f\"{language} result\")\n",
    "\n",
    "with gr.Blocks(title=f\"Port code from Python to selected language\") as interface:\n",
    "    with gr.Row(equal_height=True):\n",
    "        with gr.Column(scale=2):\n",
    "            language = gr.Dropdown(languages, value=languages[0], show_label=False)\n",
    "            compile_code = gr.TextArea(label=\"Compile Command\", lines=6)\n",
    "            get_compile = gr.Button(f\"Generate compile command for {language.value} to replace command_compile\")\n",
    "            language.change(fn=update_get_compile, inputs=language, outputs=get_compile)\n",
    "\n",
    "    with gr.Row(equal_height=True):\n",
    "        with gr.Column(scale=6):\n",
    "            python = gr.Code(\n",
    "                label=\"Python (original)\",\n",
    "                value=python_hard,\n",
    "                language=\"python\",\n",
    "                lines=26\n",
    "            )\n",
    "        with gr.Column(scale=6):\n",
    "            code_output= gr.Code(\n",
    "                label=f\"{languages[0]} (generated)\",\n",
    "                value=\"\",\n",
    "                language=\"cpp\", #rust and go not supported\n",
    "                lines=26\n",
    "            )\n",
    "            language.change(fn=update_code_output, inputs=language, outputs=code_output)\n",
    "    with gr.Row(equal_height=True):\n",
    "        python_run = gr.Button(\"Run Python\")\n",
    "        model = gr.Dropdown(models, value=models[0], show_label=False)\n",
    "        convert = gr.Button(f\"Port to {languages[0]}\")\n",
    "        code_run = gr.Button(f\"Run {languages[0]}\")\n",
    "        language.change(fn=update_convert_output, inputs=language, outputs=convert)\n",
    "        language.change(fn=update_code_run_output, inputs=language, outputs=code_run)\n",
    "\n",
    "    with gr.Row(equal_height=True):\n",
    "        with gr.Column(scale=6):\n",
    "            python_out = gr.TextArea(label=\"Python result\", lines=8)\n",
    "        with gr.Column(scale=6):\n",
    "            code_out = gr.TextArea(label=f\"{languages[0]} result\", lines=8)\n",
    "            language.change(fn=update_code_out_output, inputs=language, outputs=code_out)\n",
    "       \n",
    "    get_compile.click(fn=checkSystem, inputs=[language], outputs=[compile_code])\n",
    "    convert.click(fn=portCode, inputs=[model, python, language], outputs=[code_output])\n",
    "    python_run.click(fn=run_python, inputs=[python], outputs=[python_out])\n",
    "    code_run.click(fn=compile_and_run, inputs=[code_output], outputs=[code_out])\n",
    "    \n",
    "\n",
    "\n",
    "interface.launch(inbrowser=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
